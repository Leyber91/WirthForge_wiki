WF-TECH-003 — Real-Time Protocol (WebSockets)
🧬 Document DNA

Unique ID: WF-TECH-003

Category: TECH

Priority: P0

Dev Phase: 1

Estimated Length: ~3,000 words

Document Type: Technical Specification / Protocol Design

🔗 Dependency Matrix

Required Before This: WF-TECH-001 (System Runtime & Services – provides the orchestrator and component hooks for startup/monitoring), WF-FND-004 (The Decipher – defines real-time output events and data schemas).

Enables After This: WF-TECH-004 (State & Storage – will build on the streaming data and need this protocol for event logging and persistence), WF-TECH-006 (Security & Privacy – secure WebSocket authentication and encrypted transport), WF-UX-006 (Unified Energy Visualization – UI real-time rendering relies on this protocol), WF-UX-001 (Level 1 Lightning Strikes – base user experience using real-time feedback).

Cross-References: WF-FND-002 (Energy Framework – 60 Hz timing and frame budget guidelines), WF-FND-001 (Vision – mandates local-first, web-enhanced design), WF-FND-005 (Experience Orchestrator – progressive activation of features like multi-model “Council”), WF-FND-006 (Glossary – consistent terminology), WF-META-001 (System Timing & Template – 60 Hz update loop, template structure).

🎯 Core Objective

Define a robust WebSocket-based real-time communication protocol that links WIRTHFORGE’s local backend to its browser-based UI, delivering structured 60 Hz event streams with <5 ms median latency to the user. In essence, this specification establishes the “lifeline” between the AI’s core engine and the web interface – ensuring every frame of computation (energy updates, AI token outputs, multi-model interactions, etc.) is transmitted instantly and reliably to the client. The protocol must achieve high-frequency updates without frame loss, guarantee message ordering and delivery, and gracefully handle disconnects or slowdowns, all while preserving WIRTHFORGE’s local-first, privacy-focused philosophy (i.e. no cloud servers, all data stays on the user’s device in JSON form). By the end of this document, we will have a clear blueprint and contract for how real-time data flows from the orchestrator (Layer 3) through a FastAPI WebSocket server (Layer 4) to the browser UI (Layer 5)
GitHub
GitHub
. This blueprint will enable seamless visual feedback (like “live energy” graphs, particle effects, and token streaming) synchronized with the AI’s 60 Hz processing loop, forming the backbone for interactive user experiences in WIRTHFORGE.

📚 Knowledge Integration Checklist

60 Hz Frame Streaming: Incorporate the system timing constraints from WF-FND-002/WF-META-001 so that up to 60 messages per second can be sent to the client, aligned with the 16.67 ms frame budget of the engine
GitHub
. The protocol design must ensure each frame’s events (if any) are dispatched in that frame, and that backpressure or batching strategies handle bursts without breaking the cadence.

Decipher Event Schema Alignment: Use the structured event outputs defined in WF-FND-004 (Decipher) – e.g. energy_update, energy_field, interference, resonance, etc. – as the basis for message types. The WebSocket messages must carry these events in JSON format exactly as specified (types, fields) so that front-end and back-end share a strict contract
GitHub
. We will integrate DECIPHER’s outputs (energy metrics, pattern detections, etc.) directly into the real-time channel, ensuring no divergence between what Decipher produces and what the UI receives.

Local-First, Web-Enhanced: Design the transport with the assumption that the server and client run on the same device (localhost), with no Docker or cloud services in the core loop (per WF-FND-001’s principles). The protocol should leverage web standards (WebSocket, JSON) to interface with a browser UI, but all computation and data remain local. We must enforce that the WebSocket server binds to localhost by default (no external exposure) and that all handshake and data exchange stays within the user’s machine
GitHub
. This ensures real-time speed (low latency) and privacy, as even the initial handshake and subsequent messages never traverse an external network.

TECH-001 Hooks and Handshake: Utilize the orchestration hooks from WF-TECH-001 – for example, the orchestrator’s startup sequence and process monitors – to trigger protocol events. On startup, the orchestrator will send a handshake message (startup_complete) once core services are ready
GitHub
. Likewise, any significant process events (model loaded, or model error) should emit corresponding WebSocket messages. This ensures that the protocol not only streams AI data but also serves as a channel for system status and coordination signals, all aligned with the Zero-Config Boot sequence described in TECH-001.

Multi-Model & Progressive Features: Prepare the protocol for advanced scenarios from WF-FND-005 (Experience Orchestration) and UX Level-2+ features. This includes supporting “Council” events (when multiple AI models run in parallel) by defining channels or message types for interference patterns or consensus results. The checklist ensures we have placeholders or designs for events like interference_event and resonance_event which might not be active at Level 1 but will be needed as the user progresses to multi-model experiences
GitHub
. The protocol must be flexible to handle multiple concurrent data streams (one per model or per energy “source”) without confusion, likely through channel tagging or separate message types, and possibly allow subscription filtering if needed in the future.

JSON over Binary for Transparency: Adhere to using JSON for all data transport (no MessagePack or proprietary binary frames) as a conscious design choice for transparency and ease of debugging. We acknowledge that binary encoding could be more efficient, but maintaining human-readable JSON aligns with WIRTHFORGE’s ethos of auditability and ease of integration. The protocol should nonetheless be “performance-tuned” – meaning JSON payloads are kept minimal (e.g. numeric codes or short keys where possible) to mitigate overhead, achieving near-binary performance while retaining readability. We also note in design how a binary frame would be structured for energy events, to illustrate what we’ve optimized away, and ensure that if needed later (for extreme performance modes), a switch to binary could be done without altering semantics.

Privacy & Data Protection: Ensure that no sensitive user content is inadvertently exposed through the WebSocket messages, echoing WF-FND-004’s privacy mandate. The Decipher’s outputs sent over WS should contain only abstracted information – energy values, counts, pattern flags, timestamps, and other metrics – not raw text or user data
GitHub
. (One exception is the AI’s generated tokens themselves, which the UI needs to display; these will be handled carefully as “experience” events, and even though they may contain AI-transformed user data, they remain local to the user’s browser.) We will enforce that any text-bearing messages (like token streams) are kept separate and are only used locally, with no logging or forwarding beyond the session. This satisfies the requirement that an intercepted event stream alone should not reveal the actual conversation or documents the user is working with
GitHub
.

Reliability & Order Guarantee: Leverage the inherent ordering of WebSocket (TCP) so that events arrive in the same sequence as emitted. Our design will document how the protocol guarantees in-order delivery for each channel (ensuring, for example, that an energy_update for frame N arrives before frame N+1’s update) and exactly-once processing by the UI (the client will treat each message as authoritative and idempotent for that frame). We will also include measures for error handling – e.g., if a message is malformed or a sequence is broken by a disconnect, how the client/server recover – and for delivery acknowledgment if needed (though WebSocket itself doesn’t do per-message ACK, our application-level protocol may not require explicit acks given the local context and low loss rates).

Backpressure & Heartbeat Mechanisms: Build in knowledge from WF-FND-004 about buffering and frame-skipping. If the model produces more data than can be sent in real-time (e.g., a burst of tokens), Decipher already batches them per frame; our protocol must similarly avoid flooding the network buffer. We’ll include a backpressure policy: for example, if the client is slow to process messages or the network buffer is filling, the server can drop or coalesce older frame events to free up space (ensuring the latest state is always delivered, rather than queueing stale updates). Additionally, implement a lightweight heartbeat message on the WebSocket to periodically assure connection liveness and measure latency. The heartbeat (e.g., a small { "type": "ping", "ts": ... } or WebSocket ping frames) will allow detection of lost connections within a frame or two and trigger the reconnect logic promptly.

📝 Content Architecture

Section 1: Opening Hook – The 60 Hz Lifeline
Illustrate the real-time link between WIRTHFORGE’s core and the user’s screen. We open with a vivid scenario: the moment WIRTHFORGE boots up, an invisible handshake forms between the orchestrator (the “brain” running locally) and the browser UI (the “window” through which the user sees the AI’s energy). As the AI begins thinking (generating tokens), pulses of data are sent 60 times a second through this WebSocket lifeline, making the screen come alive with corresponding flashes of energy. The user, typing a prompt and hitting enter, sees not just text appearing, but a synchronized dance of lights and stats – all thanks to a tightly orchestrated protocol that delivers each “frame” of AI activity in under 5 milliseconds. This section hooks the reader by emphasizing how crucial the real-time protocol is: without it, the AI’s work would be invisible. With it, WIRTHFORGE achieves its signature effect – turning every bit of computation into an immediate, interactive visual experience. We also foreshadow the challenges: keeping up with a furious 60 FPS pace, never letting the connection lag or drop, and doing it all on local hardware with web technology.

Section 2: Core Concepts – Channels, Messages, and Guarantees
Define the fundamental concepts of the WebSocket protocol. We introduce the idea of dedicated channels within the single WebSocket stream, categorized by purpose: energy.* for real-time energy telemetry, experience.* for user-facing content and UX events, council.* for multi-model coordination, and reward.* for feedback and achievements. Each channel prefix corresponds to a set of message types (events) that share a common theme. We explain why this logical separation exists – it helps organize the data and allows the client to filter or prioritize different kinds of messages (for example, UI components responsible for energy visualization listen to energy.* events, whereas achievement pop-ups listen to reward.* events). Next, we detail the message structure: all messages are JSON objects containing at least a type field (e.g. "type": "energy_update") and a payload. We note that since a single physical WebSocket connection is used, every message must self-describe its type and channel (by naming convention or an explicit field like "channel": "energy"), rather than relying on separate connections. The concept of a heartbeat is introduced here as well – a special lightweight message ("type": "heartbeat") that the server sends during idle times to ensure the line stays alive and latency can be monitored. We clarify how the protocol handles ordering and idempotency: by design, messages are sent in a strict sequence aligned to frame updates and major events; the client processes them in arrival order which is guaranteed by the TCP layer. If an out-of-order scenario ever arises (e.g., after a temporary disconnect and reconnect), the client may receive a refreshed state message to resynchronize (preventing any stale data from confusing the UI). Finally, this section covers the delivery guarantees: in a local network environment, packet loss is rare, but our protocol assumes a reliable transport (WebSocket over TCP) – thus we focus on guaranteeing that if the server sent it, the client will get it or be aware of a disconnect. We mention that no explicit ACK is needed per message, simplifying the design, but the presence of periodic heartbeats and the inherent reliability of TCP suffice to detect issues.

Section 3: Implementation Details – FastAPI Server & Client Workflow
Dive into how to implement the real-time protocol in code. This section describes setting up the FastAPI backend server to handle WebSocket connections and emit events at 60 Hz. We show a code snippet of a FastAPI WebSocket endpoint (for instance, at URL /ws) where the server accepts connections from the browser
GitHub
. Once a client connects, the orchestrator’s component hooks (from Tech-001) come into play: the orchestrator immediately sends a handshake message (startup_complete) with key info like model name, hardware tier, and initial state
GitHub
. We provide a concrete example JSON of this handshake, e.g.:

{ 
  "type": "startup_complete", 
  "model": "LLaMA2-13B", 
  "tier": "Mid-Tier", 
  "version": "1.0.0", 
  "timestamp": 1692300000000 
}


This confirms to the UI that backend services are ready and conveys any initial parameters (the UI uses it to transition out of a loading screen
GitHub
). After handshake, we detail the main loop integration: the orchestrator/Decipher, running on a 60 Hz timer, invokes a send on the WebSocket for each frame’s event. Pseudocode illustrates how the server gathers data from Decipher each tick – e.g., energy values, any new tokens, etc. – and broadcasts an energy_update message to the connected client(s). We highlight that FastAPI (with uvicorn and asyncio) is well-suited for this high-frequency push, and the implementation uses non-blocking awaits to ensure the 60 Hz loop doesn’t stall if the network layer is momentarily slow. If sending to the WebSocket ever takes longer than expected (e.g., client is slow to read), the code will log a warning and apply the backpressure strategy: skipping a frame send if the previous frame is still in progress, thereby preventing piling up a queue of outdated messages. We also describe the heartbeat implementation: using either WebSocket protocol-level pings or an application-level ping message every, say, 1 second (60 frames), and expecting a pong or using the absence of ACK to detect a drop. On the client side, the browser integration is outlined: the UI code uses the standard WebSocket API (new WebSocket("ws://127.0.0.1:8145/ws")) to connect, with event handlers for onopen, onmessage, and onclose. We provide an example snippet in JavaScript demonstrating an auto-reconnect mechanism: if onclose fires unexpectedly, the client waits a short delay and tries to reconnect (with exponential backoff to avoid spamming). The client also listens for heartbeat pings and can measure the round-trip time or simply use them as no-op keep-alives. We ensure that the optional Flask central app is mentioned: while our primary design uses FastAPI for concurrency and streaming, we note that if one were to run a centralized server or a very simple deployment, a Flask-based implementation could be used (for example, Flask’s development server with a simple SocketIO or WS extension). However, Flask would likely act as a thin wrapper or proxy in such a scenario (perhaps relaying messages from a local node to remote clients), and it’s not needed for the core local use-case. By covering these implementation details, this section gives developers a clear roadmap to stand up the WebSocket service and integrate it with the existing WIRTHFORGE processes.

Section 4: Integration Points – Linking Layers 2–5 and Beyond
Explain how the WebSocket protocol interfaces with other parts of the WIRTHFORGE architecture. At Layer 3 (Orchestrator & Decipher), integration means capturing Decipher’s output each frame and packaging it into our WebSocket messages. We describe how Decipher’s structured events (as defined in FND-004) are handed off to a transport module that knows how to serialize them to JSON and push them out
GitHub
. For example, when Decipher finishes processing a frame and produces an internal energyFrame object with metrics and effects, that object is serialized into an energy_update JSON and sent to all connected clients. We ensure that any new event types introduced by Decipher (say a future resonance_alert) will be added to the protocol spec so both sides stay in sync
GitHub
. We also cover Layer 2 (Model) integration: the actual AI token stream can be integrated into the WebSocket flow. In a typical prompt cycle, the UI will send a user’s prompt to the backend (likely via a RESTful endpoint like /compile or /prompt as hinted by TECH-001
GitHub
). The model (Layer 2) then starts generating tokens. Decipher (Layer 3) converts these to energy updates, but the user also needs to see the text output. Here we outline two possible integration patterns: (1) Server-push via WebSocket – as tokens are generated, the backend could emit a experience.token_stream event carrying the latest token or partial text. This keeps all real-time data in one channel (the WebSocket) and is immediate. (2) Client-pull or direct stream – alternatively, the UI might open a separate channel (or use the same WebSocket) to get the text stream. For simplicity and coherence, we opt for using the same WebSocket: we define a message type, e.g. "type": "token_stream", that includes a text snippet (one or a batch of tokens) and perhaps a flag for end-of-stream. This event would belong to the experience.* channel, as it directly affects the user’s experience (the visible AI reply). By doing this over the WebSocket, we maintain synchronization between what the user reads and the energy animations: the token and its energy arrive together in the same timeframe. We clearly state that no raw prompt or user input is ever sent via WebSocket – the user’s prompt goes into the system via a separate secure path (likely HTTP POST to the local API), and only the AI’s output tokens (which are a transformation of user data) are streamed to the UI. This delineation protects user input privacy while still allowing output to be displayed (which is necessary for functionality). Next, integration with WF-TECH-004 (State & Storage): we mention that important events could be logged or persisted. For instance, an energy_update might be recorded in a local database for analytics, or a reward event might update a local user profile. However, to keep the protocol stateless, we do not rely on persistence for core operation; instead, Tech-004 will handle persistence separately but will consume the same data. One key integration is for reconnect recovery: if a client reconnects, it might have missed some energy_update messages. The backend, thanks to Tech-004, could fetch the latest state (for example, total energy accumulated so far, or the last known values of any long-lived effects) and send a special sync message upon reconnection. This could be as simple as re-sending the last energy_update (which contains cumulative values) or a dedicated "type": "state_snapshot" event with current totals and statuses. We ensure that our protocol spec includes this concept so that Tech-004 can implement it. Integration with multi-model orchestration (the Council, Level 2+ from UX docs) is also described: when multiple models are generating in parallel, Decipher might produce events like interference_event (when their energy streams interact) or simply separate energy_update entries for each model stream. We outline that the protocol can handle multiple model identifiers. For example, energy_update events could include a field indicating which model or stream they pertain to (e.g., modelId), and interference/resonance events would naturally belong to the council.* channel. This way, the UI can, for instance, show a visualization of two streams merging or colliding. We cite that these advanced phenomena (defined conceptually in FND-004 and FND-005) will be transmitted using our real-time channel when active. Finally, we discuss integration with the User Experience layer (Layer 5): essentially, this protocol is the contract the front-end must implement. We ensure that messages have a stable schema so that front-end developers (as defined in UX-006 spec) can build a reliable client. We mention a couple of usage examples on the UI side: e.g., on receiving an energy_update with certain values, the UI triggers an animation to update the on-screen “energy meter” or spawn particles; on receiving a reward_event (say, "type": "reward_unlocked", "badge": "First Lightning Strike"), the UI shows a notification to the user celebrating the achievement. By covering these integration points, we guarantee that the WebSocket protocol is not an island, but a well-integrated piece of the whole architecture, triggering the right downstream effects in the UI and aligning with upstream data from the AI engine.

Section 5: Validation & Metrics – Ensuring Performance and Reliability
Lay out how we will test and validate the real-time protocol. First, we define performance metrics: the latency between Decipher producing an event and the UI receiving it should be under 5 ms median (with perhaps 10 ms as a P99 outlier bound) on a typical localhost setup. We will validate this by instrumenting timestamps – e.g., the server can timestamp each message payload with its send time, and the client can log upon receive; analyzing these logs should show the distribution of delays. An automated test harness can run a long generation session (60 Hz updates for, say, 60 seconds) and calculate median and tail latencies, ensuring they meet the <5 ms median goal (in practice, on localhost, we expect ~1–2 ms median)
GitHub
. Next, we verify the throughput: the protocol must sustain 60 messages per second without loss. We’ll perform a frame rate stability test similar to that in Tech-001’s startup validation – running the system under load and confirming that we get ~60 messages/sec delivered, with no significant drops. The orchestrator’s logs or an internal counter (frame send count vs. frame number) will flag if any frames were skipped due to backpressure. Some intentional stress tests will be included: for example, generate a burst of 200 tokens in one second and confirm that the system either batches them into the 60 frames or at worst drops a few frames but never crashes or stalls. We also include a schema compliance test: using the JSON schemas delivered with this document, we will validate that every message sent over the WebSocket conforms to its schema definition. This can be done by hooking a validator in the test client or server (in non-production mode) that checks outgoing messages. Each event type (startup_complete, energy_update, token_stream, interference_event, etc.) will have a schema (Draft-07 JSON Schema) describing required fields and data types; part of our CI tests will involve sending sample messages (or actual ones from a dry-run) through a validator. This ensures the implementation hasn’t deviated from the spec and that front-end and back-end remain in lockstep regarding message formats
GitHub
. Another critical aspect is reconnect and fault tolerance: we will simulate network drops to verify the FSM (finite state machine) for reconnection behaves correctly. For instance, have the test client disconnect mid-generation and reconnect after 2 seconds – the expected outcome is that the server allows reconnection (perhaps generating a new handshake or resume message) and the UI continues receiving updates without duress. We check that upon reconnection, either the missed frames are not crucial (because the energy visualization continues from current state) or a state sync is provided. We also test improper scenarios: if the client attempts to send an unsupported message (the protocol currently mostly sends server→client, but if client->server messages like user feedback are later allowed), the server should safely ignore or reject it without breaking the connection. Ordering guarantees are implicitly tested by ensuring frame numbers or timestamps in messages increase monotonically; if any out-of-order sequence is detected by the client, it would log an error – we aim to see none. We also measure resource usage to validate that the WebSocket handling doesn’t consume undue CPU or memory: under steady 60 Hz load, the FastAPI server’s overhead for encoding JSON and context switching should be minimal (we expect the bottleneck to be the AI or Decipher, not the WS). However, we’ll confirm that enabling the stream doesn’t drop the frame rate. This can be tested by running the system with the WebSocket on vs off and measuring if Decipher’s frame loop stays within the 16.67 ms budget in both cases. The acceptance criterion is that the addition of streaming I/O does not cause frame overruns beyond the allowed threshold (e.g., if frame processing time averages say 12 ms without streaming and maybe 13 ms with streaming, that’s fine; if it jumped to 20 ms, that’s a failure). Lastly, we validate graceful degradation: scenarios where the UI is not connected. If no client is connected, the backend should still run (the energy loop updates internal state but doesn’t waste time serializing messages). We test that running a generation with no UI connected causes no errors – the system should detect no active socket and skip sending, or simply no send happens because no one is listening. Similarly, if a client disconnects, the server should clean up resources and not hold stale references. We will use tools like memory profilers to ensure a connect/disconnect loop doesn’t leak memory or file descriptors. By satisfying these validation criteria, we ensure the WebSocket protocol not only works on paper but is robust in practice: it meets the real-time performance bar, stays in sync with the rest of the system, and fails gracefully when needed (with quick recovery and no data corruption).

🎨 Required Deliverables

To fully realize and document the real-time WebSocket protocol, we will produce the following deliverables:

Documentation Text: The complete technical specification (this document) following the universal template, plus an executive summary that highlights the key aspects of the protocol for quick reference. The summary will concisely describe how the WebSocket connection is established, the role of each channel (energy, experience, council, reward), and the guarantees of 60 Hz delivery and low latency. This ensures that both developers and stakeholders can grasp the essence of WF-TECH-003 at a glance.

JSON Schema Definitions: A machine-readable schema file (e.g. WF-TECH-003-event-schemas.json) containing Draft-07 JSON Schema definitions for all event types used in the protocol. This includes schemas for messages like startup_complete, energyUpdateEvent (energy.update), tokenStreamEvent (experience.token), interferenceEvent (council.interference), resonanceEvent (council.resonance), energyFieldEvent (energy.field), rewardEvent (reward.*), and errorEvent. Each schema will define the expected JSON structure (fields, data types, required vs optional fields) and incorporate common definitions (timestamps format, modelId, etc.). These schemas serve as a source of truth for front-end and back-end implementation and will be used in testing to validate message compliance.

Mermaid Diagrams: Visual diagrams illustrating the protocol operation. Specifically, a protocol lifecycle sequence diagram showing the interaction from startup through normal operation to disconnect (e.g., Browser UI → WebSocket connect → handshake startup_complete → continuous energy_update messages → occasional token_stream and other events → heartbeat pings → abnormal disconnect → reconnect sequence). This could be delivered as WF-TECH-003-lifecycle.mmd (Mermaid source) and an exported SVG. Additionally, a state machine diagram for the WebSocket connection (the heartbeat/reconnect FSM) will be provided (e.g., WF-TECH-003-connection-fsm.mmd), depicting states like Disconnected, Connecting, Connected, Reconnecting and transitions (connect success, connection lost, retry timers). These visuals will help developers understand the dynamic behavior of the connection and are assets for the documentation.

Code Stubs and Examples: Reference implementation snippets demonstrating critical parts of the protocol. This includes a Python code stub for the FastAPI WebSocket endpoint (e.g., code/WF-TECH-003/ws_server.py) showing how to accept connections and send messages in the 60 Hz loop using asyncio. We will also include a simplified browser client example (perhaps as a JavaScript snippet or a small HTML file, code/WF-TECH-003/client-example.html) that implements the auto-reconnect logic and handles incoming messages by channel. Moreover, code illustrating the backpressure handling (e.g., how the server might drop a frame if websocket.send() is still running from the previous frame) will be given in pseudocode. Any unique algorithms, like merging multiple tokens into one frame event or generating a minimal JSON payload, will be highlighted in these snippets. Including these code examples ensures that the abstract protocol is backed by concrete guidance for implementers.

Test Suite (Specs): A set of test cases or scripts designed to validate the protocol. We will provide a test specification document (or inline in this doc’s Validation section) detailing tests such as: connecting and receiving the handshake, measuring message latency, simulating lost connections, and verifying schema compliance. If possible, an actual script (e.g., code/WF-TECH-003/test_latency.py) might be delivered to automate measuring the <5 ms median latency by sending timestamped ping-pong messages. Another script could simulate a client that floods the server with prompts to test throughput (ensuring the server and protocol handle it without breaking 60 Hz updates). These tests reinforce that the quality criteria are not just theoretical but are checked in practice.

Logging and Monitoring Configuration: As part of the deliverables, we ensure that the WebSocket server includes adequate logging (at least in debug mode) to trace connections and message flow. For example, logs for “Client connected/disconnected”, “Sent energy_update frame 123 (timestamp X) to client”, and warnings if latency or send times exceed a threshold. We will document how to enable and interpret these logs. Additionally, if applicable, we provide a small configuration snippet for monitoring (maybe integration with a web UI console showing connection status and latency). This is not a separate product but is included in the documentation to guide operators and developers in troubleshooting the real-time channel.

All deliverables will adhere to the WIRTHFORGE documentation standards (file naming mirroring WF-TECH-001 patterns, proper JSON formatting, and inclusion in the project’s asset manifest). By producing these artifacts, we ensure that anyone implementing or reviewing the WF-TECH-003 protocol has all necessary reference materials: formal schemas, visual aids, code examples, and tests.

✅ Quality Validation Criteria

To verify that this document and the proposed protocol meet WIRTHFORGE’s standards and requirements, we will evaluate it against the following quality criteria:

Correctness & Completeness: The protocol design must cover all key use cases and match the project’s needs as identified in Tech-001 and Decipher (FND-004). We will review whether every item in the Required Deliverables list (channel definitions, event types, heartbeat, diagrams, etc.) has been thoroughly addressed in the document. Each message type defined in Decipher’s design
GitHub
 (e.g., energy_update, energy_field, interference, etc.) appears in this spec with a clear definition, ensuring no gap between what Decipher emits and what the WebSocket transmits. Additionally, we confirm that we’ve planned for error cases (e.g., connection loss, malformed data) and included recovery procedures so the design isn’t only covering the “happy path.” The presence of the errorEvent schema and reconnect logic documentation will serve as evidence of this completeness.

Alignment with Architecture Principles: We will cross-check that the protocol strictly respects the layered architecture and local-first principles. For example, Layer Separation: the UI (Layer 5) only communicates with the backend via this Layer 4 protocol and doesn’t reach directly into the model or orchestrator – verified by the fact that all real-time data goes through the WebSocket and any model control stays on defined API endpoints
GitHub
. Local-First: ensure that nothing in the design implies a need for external connectivity; indeed, our spec binds to localhost and uses no external messaging systems. No-Docker: confirm the implementation uses native Python and standard libs (FastAPI) without container-specific assumptions. We also ensure that our protocol discussions have consistently reinforced privacy (no unsolicited data leaving the machine). Any instance in the text or diagrams that might imply external communication will be scrutinized and removed unless it’s clearly optional (and user-initiated). This criterion is met when the protocol can be implemented and run entirely offline on a user’s device, which our design explicitly supports.

Performance and Timing Justification: We assess whether the document provides sufficient reasoning and evidence that the 60 Hz, <5 ms latency goal is achievable. This includes references to known performance of local WebSockets (which are typically easily within microseconds to low milliseconds latency on localhost) and the measures we described to keep overhead low (like minimal JSON payloads and skipping frames if needed). If needed, we’ll include a brief empirical result (from prototype testing) in the document or footnotes, e.g., “in testing, median round-trip latency was 1.8 ms on local loopback” to give confidence. The quality check here is that the spec doesn’t just state the goal but inspires confidence in meeting it – through design choices and possibly preliminary benchmarks. Moreover, the plan to measure and enforce this (via the test suite, see Validation section) should be clearly stated, which it is.

Terminology and Schema Consistency: All terms and message schemas must be consistent with the WIRTHFORGE glossary and other documents. We will verify that we used the exact event names as decided (for example, if WF-FND-004 says energyUpdateEvent, we use the same camel-case or snake-case consistently). Terms like “Energy Unit (EU)”, “Frame”, “Council”, “Tier”, etc., should appear with the meaning given in foundational docs. The first time we mention any important concept, we either define it or ensure it’s common knowledge from earlier docs (and possibly provide a reference). A quality check will be to scan the document for any undefined acronyms or ambiguous phrases. If any new term was introduced (say we coined “heartbeat ping” or “latency budget”), we will add these to the glossary WF-FND-006 as part of the post-generation protocol. Consistency extends to JSON key naming: e.g., if elsewhere in WIRTHFORGE events the timestamp field is always timestamp (epoch ms), we use the same; if model IDs are strings like “modelId”, we replicate that format. Meeting this criterion means a developer can read this spec alongside Decipher’s spec and see no contradictions or mysterious new terms – everything lines up.

Robustness and Failure Handling: We validate that the spec covers how the system behaves under failure modes. This includes client disconnects, server overload, JSON parsing errors, etc. Our document explicitly describes the reconnect flow (with FSM), the backpressure strategy for overload, and the errorEvent for sending error info. During quality review, we’ll simulate each failure mode against the spec: e.g., “What happens if the UI crashes mid-stream?” → the spec says the server notices the socket close (via error/close event) and the state machine goes to Reconnecting or waits for a new connection; nothing in the core loop breaks because it’s designed to handle no active client. Or “What if a token contains an invalid Unicode character that could break JSON?” → presumably the JSON encoder will handle it (or we ensure text is UTF-8), and if not, the error would be caught and an errorEvent could be sent. By enumerating these, we ensure no known failure scenario is unaddressed. Our criteria is satisfied if for every “what if” we can find a section in the doc that explains the handling or we explicitly state it’s out of scope but acceptable (e.g., if the network is so slow that even 1 message/sec gets through – unlikely locally – we might not specifically cover that beyond saying the experience would degrade).

Documentation Format and Clarity: Finally, we ensure this document itself adheres to the WIRTHFORGE documentation quality standards. That means it follows the universal template structure (which it does, from DNA through Post-Gen), it is written in clear, concise language (short paragraphs, lists for important items), and it provides a logical flow. A specific check: the Content Architecture outlined sections 1–5, and indeed our detailed sections followed that outline – we will confirm each planned section was expanded in order, to maintain coherence. Additionally, any citations to other docs (as provided in this draft) will be verified for accuracy and relevance, ensuring they reinforce our points and not misquote. Clarity will be judged by whether a new engineer joining the project could read this and understand what needs to be built for the WebSocket layer without constantly asking for clarification. We’ve included diagrams, examples, and references to aid understanding; the quality review will make sure those are sufficient and placed appropriately (e.g., diagrams are labeled and described, code snippets are explained). Passing this criterion means the document is not only technically sound but also easy to use as a reference during implementation.

By rigorously applying these validation criteria during review, we aim to certify that WF-TECH-003 is a solid, reliable specification that aligns with WIRTHFORGE’s vision and can be implemented with confidence. Each criterion serves as a checkpoint to catch any oversight, ensuring that by the time this document is finalized, it upholds the high standard of quality expected in the project.

🔄 Post-Generation Protocol

After drafting and approving this technical document, a series of follow-up actions will integrate WF-TECH-003 into the broader WIRTHFORGE project ecosystem:

Glossary Updates: We will update WF-FND-006 (the master glossary) with any new terminology introduced in this spec. For instance, terms like “WebSocket Handshake”, “Heartbeat Ping”, “Council Channel”, or specific event names (energy_update, etc.) should be added or refined in the glossary with clear definitions. We will also ensure that existing entries for terms such as “Energy Frame” or “Backpressure” encompass the context given here (e.g., noting that energy frames are transmitted via WebSocket at 60 Hz). This step guarantees consistency and helps future readers quickly find the meaning of terms used in multiple docs. Each glossary addition will include a reference back to this document for traceability.

Asset Registration: All diagrams and schema files produced will be checked into the repository and referenced in the documentation index. For example, the Mermaid source for the lifecycle diagram (WF-TECH-003-lifecycle.mmd) will be placed in the assets/diagrams/ directory and an SVG export will be generated for use in rich displays. The JSON schema file WF-TECH-003-event-schemas.json will go into assets/schemas/ (or a similar data/ directory as per project convention), and we’ll add an entry to the project’s asset manifest linking it to this document. The code snippets or stubs (if we create standalone files, like the example client or server stub) will be added under a code/WF-TECH-003/ folder. We will update doc-index.json and any manifest or table of contents so that this document and its auxiliary files are properly catalogued (ensuring the “docs/{id}/document.md” entry for WF-TECH-003 is present, etc.). Essentially, this step formalizes the outputs of our deliverables section into the project’s structure.

Dependency Graph and Cross-Refs: Now that WF-TECH-003 is defined, any documents that “consume” or rely on it will be updated to reference it. For instance, WF-TECH-004 (State & Storage) and WF-UX-006 (Energy Visualization) in their drafts will likely have placeholders for hooking into the real-time protocol – we will make sure they cite WF-TECH-003 where appropriate and assume the message structures from this spec. If there were any TODOs or forward references in those docs (like “see TECH-003 for WebSocket details”), we can now fill those in with proper context or even embed the relevant schema. Moreover, the dependency matrix in those docs should list WF-TECH-003 as fulfilled. In the project’s master dependency graph (perhaps maintained in WF-META-001 or a separate overview), we ensure WF-TECH-003 is marked complete and its “enables” links (TECH-004, UX-006, UX-001) are active. This solidifies WF-TECH-003’s place in the doc hierarchy and informs other workstreams that they can build on it.

Version Bump and Changelog: We will assign a version number to this spec (likely 1.0.0 for its initial complete version) and create a changelog entry. The changelog (CHANGELOG-WF-TECH-003.md) will briefly summarize the creation of the document and highlight any notable decisions (e.g., “Decided on JSON over MessagePack, four channel structure defined, heartbeat mechanism included, etc.”). If during integration any adjustments are needed (for example, if testing reveals we should tweak something), those will be noted and the version incremented accordingly. Maintaining a changelog is part of the documentation protocol to track evolution over time, as specified in WF-META-001 (which mandates SemVer versioning for docs and assets).

Prototype and Feedback Loop: Although not a formal document step, after spec completion, a prototype implementation of the WebSocket server/client should be built to validate the design. We include in the post-gen notes that the team should implement a minimal end-to-end test of the protocol (perhaps using the provided code stubs) to ensure nothing was overlooked. Any feedback from that prototype (say, needing an additional field in an event, or discovering a corner case in reconnection) can be fed back into an updated version of this doc. This agile loop ensures the spec stays living and practical. We note that any such changes will be made in accordance with the governance guidelines – meaning we’d update the doc, bump the version, and notify dependent teams.

Cascade to UI Implementation (UX-006/UX-001): Now that the protocol is defined, the front-end team (or UX spec authors) can finalize how the UI consumes these WebSocket events. As part of post-generation, we’ll have a brief sync with the UX document owners to make sure the event names and structures match what they need for rendering. For example, if the UI spec wanted an event called lightning_strike and we call it energy_update, we either reconcile the naming or note the translation. Ideally, we maintain one-to-one naming to avoid confusion (likely the UI spec will just use the same event names). This coordination prevents any mismatch between backend and frontend expectations.

Security Review: Although this protocol runs locally, we will do a light security review as a post-step. We’ll confirm that using a WebSocket on localhost with no authentication is acceptable under our threat model (it should be, because if an attacker has local access, the whole system is at risk anyway). If any security considerations came up (e.g., if we allow cross-origin connections for a remote UI, as our CORS middleware suggests we permit localhost:3000
GitHub
), we document how that’s constrained (only specific origins). We’ll involve the Security lead (who might be authoring WF-TECH-006) to double-check that nothing in WF-TECH-003 violates any privacy or security requirement – for instance, ensuring that no sensitive info is accidentally logged or that the WebSocket can’t be easily hijacked (which on localhost is extremely unlikely). Any recommendations from that review (like “always use ws://localhost and not listen on 0.0.0.0 unless user explicitly configures for LAN access”) will be added either to this doc or to the Security doc, as appropriate.

By executing this Post-Generation Protocol, we ensure that WF-TECH-003 doesn’t remain an isolated spec but becomes an active, implemented part of WIRTHFORGE’s system. We treat the document as a living contract – one that is now shared with all stakeholders (developers, testers, UX designers) and will be maintained through the project’s life cycle. The end result is a synchronized state across documentation, code, and team understanding: the real-time WebSocket pipeline is specified here, built in the codebase, and referenced wherever needed for a cohesive implementation.