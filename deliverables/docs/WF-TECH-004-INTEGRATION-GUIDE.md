# WF-TECH-004 Integration Guide
**WIRTHFORGE State Management & Storage System**

## Document Information
- **Document ID**: WF-TECH-004-INTEGRATION-GUIDE.md
- **Version**: 1.0.0
- **Created**: 2025-08-17
- **Category**: Integration Documentation
- **Dependencies**: WF-TECH-004-STATE-STORAGE.md

## Overview

This guide provides developers with practical instructions for integrating and using the WIRTHFORGE State Management & Storage system. It covers setup, configuration, API usage, and best practices for implementing the local-first, event-sourced storage subsystem.

## Quick Start

### 1. Database Setup

```bash
# Create the database schema
sqlite3 wirthforge_state.db < deliverables/code/WF-TECH-004-DBSchema.sql

# Verify schema creation
sqlite3 wirthforge_state.db "SELECT value FROM schema_info WHERE key = 'version';"
```

### 2. Python Dependencies

```bash
pip install asyncio sqlite3 json jsonschema pyyaml
```

### 3. Basic Integration

```python
from WF_TECH_004_snapshot_recovery import StateManager
import asyncio

async def main():
    # Initialize state manager
    state_manager = StateManager("wirthforge_state.db")
    
    if await state_manager.initialize():
        print("State manager initialized successfully")
        
        # Your application logic here
        
        # Graceful shutdown
        await state_manager.shutdown()

if __name__ == "__main__":
    asyncio.run(main())
```

## Architecture Integration

### Orchestrator Integration (WF-TECH-001)

The state manager integrates with the system orchestrator during startup and shutdown:

```python
class WirthForgeOrchestrator:
    def __init__(self):
        self.state_manager = None
        
    async def startup(self):
        # Initialize state manager early in startup sequence
        self.state_manager = StateManager(self.config.db_path)
        
        if not await self.state_manager.initialize():
            raise RuntimeError("Failed to initialize state manager")
            
        # Continue with other component initialization
        await self.init_decipher()
        await self.init_websocket_server()
        
    async def shutdown(self):
        # Shutdown in reverse order
        await self.websocket_server.shutdown()
        await self.decipher.shutdown()
        await self.state_manager.shutdown()
```

### Decipher Engine Integration (WF-FND-004)

The Decipher engine generates events that the state manager captures:

```python
class DecipherEngine:
    def __init__(self, state_manager):
        self.state_manager = state_manager
        
    async def process_frame(self):
        # Calculate energy for this frame
        energy_delta = self.calculate_energy()
        
        # Create energy update event
        event = {
            'session_id': self.current_session_id,
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'type': 'energy.update',
            'data': {
                'energy': energy_delta,
                'accumulator': self.total_energy,
                'model_id': self.active_model_id,
                'fps': self.current_fps,
                'frame_budget_used': self.frame_time_ms
            },
            'frame_id': self.frame_count,
            'energy_delta': energy_delta
        }
        
        # Queue event for persistence (non-blocking)
        await self.state_manager.event_queue.put(event)
        
        # Update in-memory state
        self.state_manager.current_state.energy_accumulator.total_energy += energy_delta
        self.state_manager.current_state.frame_state.energy_current = energy_delta
```

### WebSocket Integration (WF-TECH-003)

Events are broadcast to UI clients via WebSocket:

```python
class WebSocketHandler:
    def __init__(self, state_manager):
        self.state_manager = state_manager
        self.clients = set()
        
    async def handle_client_connection(self, websocket):
        self.clients.add(websocket)
        
        # Send initial state sync
        if self.state_manager.current_state:
            await websocket.send(json.dumps({
                'type': 'state.sync',
                'data': asdict(self.state_manager.current_state)
            }))
            
    async def broadcast_event(self, event):
        if self.clients:
            message = json.dumps(event)
            await asyncio.gather(
                *[client.send(message) for client in self.clients],
                return_exceptions=True
            )
```

## Event Generation Patterns

### Energy Events

```python
# Energy update (generated by Decipher at ~10Hz)
energy_event = {
    'session_id': session_id,
    'timestamp': datetime.now(timezone.utc).isoformat(),
    'type': 'energy.update',
    'data': {
        'energy': 4.2,
        'accumulator': 847.3,
        'model_id': 'ollama/llama2:7b',
        'fps': 60.0,
        'frame_budget_used': 12.3,
        'diversity_index': 0.847,
        'token_count': 23
    },
    'frame_id': 1234,
    'energy_delta': 4.2
}
```

### User Events

```python
# User prompt event
user_event = {
    'session_id': session_id,
    'timestamp': datetime.now(timezone.utc).isoformat(),
    'type': 'user.prompt',
    'data': {
        'prompt_id': 'prompt_abc123',
        'interface': 'text',
        'length': 45,
        'truncated': False,
        'hash': hashlib.sha256(prompt_text.encode()).hexdigest()[:16],
        'language': 'en',
        'intent': 'question'
    }
}
```

### Pattern Events

```python
# Interference pattern event
interference_event = {
    'session_id': session_id,
    'timestamp': datetime.now(timezone.utc).isoformat(),
    'type': 'pattern.interference',
    'data': {
        'models_involved': ['ollama/llama2:7b', 'ollama/mistral:7b'],
        'interference_type': 'constructive',
        'strength': 0.73,
        'frequency': 42.5,
        'duration_ms': 150.0
    },
    'frame_id': 4567
}
```

## Configuration

### Database Configuration

```python
# SQLite (default)
config = {
    'database': {
        'type': 'sqlite',
        'path': 'wirthforge_state.db',
        'backup_interval': 3600,  # seconds
        'vacuum_interval': 86400  # seconds
    }
}

# MariaDB (optional, local only)
config = {
    'database': {
        'type': 'mariadb',
        'host': '127.0.0.1',
        'port': 3306,
        'database': 'wirthforge',
        'user': 'wirthforge',
        'password': 'local_password',
        'socket': '/var/run/mysqld/mysqld.sock'  # Unix socket preferred
    }
}
```

### Performance Configuration

```python
config = {
    'performance': {
        'event_batch_size': 15,
        'event_batch_timeout_ms': 200,
        'max_queue_size': 1000,
        'snapshot_interval_events': 1000,
        'snapshot_interval_seconds': 60,
        'cleanup_old_events_days': 90
    }
}
```

### Privacy Configuration

```python
config = {
    'privacy': {
        'store_raw_content': False,  # Hash sensitive content by default
        'audit_mode': False,         # Full logging for debugging
        'export_includes_content': False,  # Privacy-safe exports
        'auto_purge_sessions_days': None   # No automatic purge
    }
}
```

## API Reference

### StateManager Class

#### Initialization
```python
state_manager = StateManager(db_path="wirthforge_state.db")
await state_manager.initialize()
```

#### Event Logging
```python
# Queue event for persistence
await state_manager.event_queue.put(event_dict)

# Direct event logging (use sparingly)
await state_manager.log_event(event_type, event_data, session_id)
```

#### Snapshot Management
```python
# Create snapshot
snapshot_id = await state_manager.create_snapshot(session_id, "periodic")

# Load snapshot for recovery
await state_manager.recover_from_crash(session_id)
```

#### State Access
```python
# Get current state
current_state = state_manager.current_state

# Update in-memory state
state_manager.current_state.energy_accumulator.total_energy += energy_delta
```

### Backup CLI Usage

```bash
# Create full backup
python WF-TECH-004-backup-cli.py wirthforge_state.db backup backup.zip --format zip

# Export specific session
python WF-TECH-004-backup-cli.py wirthforge_state.db export SESSION_ID session_export.yaml

# List recent sessions
python WF-TECH-004-backup-cli.py wirthforge_state.db list --limit 50

# Purge old session (with confirmation)
python WF-TECH-004-backup-cli.py wirthforge_state.db purge --session SESSION_ID

# Complete data wipe (dangerous)
python WF-TECH-004-backup-cli.py wirthforge_state.db purge --all
```

### Validation and Debugging

```bash
# Validate database integrity
python WF-TECH-004-validate.py wirthforge_state.db --schema-path assets/schemas/

# Replay session for debugging
python WF-TECH-004-replay.py --database wirthforge_state.db --session SESSION_ID --verbose

# Replay from JSON export
python WF-TECH-004-replay.py --json session_export.json --verbose
```

## Best Practices

### Event Design

1. **Keep events atomic**: Each event should represent a single, indivisible change
2. **Include sufficient context**: Events should be self-contained for replay
3. **Use consistent timestamps**: Always use UTC with microsecond precision
4. **Validate against schemas**: Use JSON Schema validation before persistence

### Performance Optimization

1. **Batch writes**: Use the background writer's batching mechanism
2. **Avoid synchronous I/O**: Never block the 60Hz loop for database operations
3. **Monitor queue depth**: Alert if event queue grows beyond thresholds
4. **Regular maintenance**: Schedule periodic VACUUM and ANALYZE operations

### Error Handling

1. **Graceful degradation**: Continue operation even if some events can't be persisted
2. **Retry with backoff**: Implement exponential backoff for transient failures
3. **Circuit breaker**: Temporarily disable persistence if database is unavailable
4. **Alert on errors**: Log and alert on persistent storage failures

### Security and Privacy

1. **Hash sensitive content**: Never store raw user prompts or AI responses by default
2. **Validate inputs**: Sanitize all data before database insertion
3. **Audit access**: Log all data export and purge operations
4. **Regular backups**: Automated backups with user control

## Troubleshooting

### Common Issues

#### Database Lock Errors
```python
# Symptom: "database is locked" errors
# Solution: Implement retry with backoff
async def write_with_retry(self, operation, max_retries=3):
    for attempt in range(max_retries):
        try:
            return await operation()
        except sqlite3.OperationalError as e:
            if "database is locked" in str(e) and attempt < max_retries - 1:
                await asyncio.sleep(0.1 * (2 ** attempt))  # Exponential backoff
                continue
            raise
```

#### Memory Growth
```python
# Symptom: Unbounded memory growth
# Solution: Limit event queue size and implement backpressure
if self.event_queue.qsize() > self.max_queue_size:
    # Drop oldest non-critical events
    while self.event_queue.qsize() > self.max_queue_size * 0.8:
        try:
            old_event = self.event_queue.get_nowait()
            if old_event['type'] not in ['energy.update', 'health.heartbeat']:
                # Re-queue critical events
                await self.event_queue.put(old_event)
                break
        except asyncio.QueueEmpty:
            break
```

#### Frame Drops
```python
# Symptom: Frame processing exceeds 16.67ms budget
# Solution: Profile and optimize hot paths
import cProfile
import pstats

def profile_frame_processing():
    profiler = cProfile.Profile()
    profiler.enable()
    
    # Your frame processing code here
    
    profiler.disable()
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(10)  # Top 10 slowest functions
```

### Monitoring and Alerts

```python
# Key metrics to monitor
metrics = {
    'event_queue_depth': state_manager.event_queue.qsize(),
    'write_latency_ms': last_write_duration * 1000,
    'frame_processing_ms': frame_duration * 1000,
    'memory_usage_mb': psutil.Process().memory_info().rss / 1024 / 1024,
    'database_size_mb': os.path.getsize(db_path) / 1024 / 1024
}

# Alert thresholds
alerts = {
    'event_queue_depth > 500': 'warning',
    'write_latency_ms > 50': 'warning',
    'frame_processing_ms > 16.67': 'critical',
    'memory_usage_mb > 4096': 'warning'
}
```

## Testing Integration

### Unit Tests
```python
import pytest
from WF_TECH_004_snapshot_recovery import StateManager

@pytest.mark.asyncio
async def test_basic_event_logging():
    state_manager = StateManager(":memory:")  # In-memory database for testing
    await state_manager.initialize()
    
    event = {
        'session_id': 'test_session',
        'timestamp': '2025-08-17T20:00:00.000Z',
        'type': 'energy.update',
        'data': {'energy': 5.0, 'accumulator': 5.0},
        'energy_delta': 5.0
    }
    
    await state_manager.event_queue.put(event)
    await asyncio.sleep(0.5)  # Allow background processing
    
    # Verify event was persisted
    events = state_manager.db.execute(
        "SELECT * FROM event WHERE session_id = ?", 
        ('test_session',)
    ).fetchall()
    
    assert len(events) == 1
    assert events[0]['type'] == 'energy.update'
```

### Integration Tests
```python
@pytest.mark.asyncio
async def test_full_session_lifecycle():
    # Test complete session from start to finish
    state_manager = StateManager("test_integration.db")
    await state_manager.initialize()
    
    session_id = "integration_test_session"
    
    # Start session
    await state_manager.start_session(session_id, "default")
    
    # Generate events
    for i in range(100):
        event = create_test_energy_event(session_id, i)
        await state_manager.event_queue.put(event)
    
    # Create snapshot
    snapshot_id = await state_manager.create_snapshot(session_id)
    assert snapshot_id is not None
    
    # End session
    await state_manager.end_session(session_id)
    
    # Verify data integrity
    validator = DataValidator("test_integration.db")
    assert validator.run_validation()
```

## Migration Guide

When upgrading to new schema versions:

1. **Backup existing data**:
   ```bash
   python WF-TECH-004-backup-cli.py wirthforge_state.db backup pre_migration_backup.zip
   ```

2. **Run migration script**:
   ```bash
   sqlite3 wirthforge_state.db < WF-TECH-004-migration-v1.1.0.sql
   ```

3. **Validate migration**:
   ```bash
   python WF-TECH-004-validate.py wirthforge_state.db
   ```

4. **Update application code** to use new schema features

5. **Test thoroughly** before production deployment

## Support and Resources

- **Technical Specification**: WF-TECH-004-STATE-STORAGE.md
- **Database Schema**: deliverables/code/WF-TECH-004-DBSchema.sql
- **JSON Schemas**: assets/schemas/WF-TECH-004-*.json
- **Test Specifications**: deliverables/docs/WF-TECH-004-state-consistency.spec.md
- **Example Code**: All Python scripts in deliverables/code/
- **Audit Example**: deliverables/docs/WF-TECH-004-audit-example.yaml

For additional support, refer to the WIRTHFORGE documentation repository or contact the development team.
