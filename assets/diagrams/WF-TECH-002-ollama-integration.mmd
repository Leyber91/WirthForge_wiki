sequenceDiagram
    participant API as ğŸŒ FastAPI Server
    participant Adapter as ğŸ”Œ Ollama Adapter
    participant Ollama as ğŸ¤– Ollama Server
    participant Dec as âš¡ DECIPHER Engine
    participant WS as ğŸ”Œ WebSocket Stream
    participant UI as ğŸ–¥ï¸ Browser UI

    Note over API,UI: ğŸ¤– WIRTHFORGE Local AI Integration Flow (TECH-002)

    rect rgb(59, 130, 246, 0.1)
        Note over API,Ollama: ğŸ“¦ Phase 1: Model Loading & Validation
        API->>Adapter: ğŸ¯ Load Model Request (Hardware Tier)
        activate Adapter
        Adapter->>Adapter: ğŸ·ï¸ Validate Hardware Tier Policy
        Adapter->>Ollama: ğŸ“¥ POST /api/pull {model, tier_config}
        activate Ollama
        
        loop Model Download Progress
            Ollama->>Adapter: ğŸ“Š Download Progress (%)
            Adapter->>API: ğŸ”„ Loading Status Updates
            API->>WS: ğŸ“ˆ model_loading Event
            WS->>UI: ğŸ¯ Progress Indicator
        end
        
        Ollama->>Adapter: âœ… Model Ready (Memory: 4.2GB)
        Adapter->>API: ğŸŸ¢ Load Complete + Model Specs
        API->>WS: ğŸ‰ model_ready Event
        WS->>UI: ğŸš€ Model Available Notification
        deactivate Ollama
    end

    rect rgb(16, 185, 129, 0.1)
        Note over API,UI: âš¡ Phase 2: Real-Time Token Generation (60Hz Target)
        API->>Adapter: ğŸ¯ Generate Request + Energy Config
        Note right of API: ğŸ“ Request Schema:<br/>{<br/>  "model": "llama2:13b",<br/>  "prompt": "user input",<br/>  "stream": true,<br/>  "energy_tracking": true<br/>}
        
        Adapter->>Ollama: ğŸš€ POST /api/generate (streaming)
        activate Ollama
        
        loop Token Stream (16.67ms Target Frame Budget)
            Ollama->>Adapter: ğŸ¯ Token + Rich Metadata
            Note right of Ollama: ğŸ“Š Token Data:<br/>{<br/>  "response": "quantum",<br/>  "done": false,<br/>  "eval_duration": 1234,<br/>  "logprobs": [-2.3, -1.8],<br/>  "entropy": 0.847<br/>}
            
            Adapter->>Dec: âš¡ Token + Timing + Probability Data
            activate Dec
            Dec->>Dec: ğŸ§® Calculate Energy E(t)
            Note right of Dec: ğŸ”¬ Energy Formula:<br/>E(t) = Î£ w_i Ã— log(1 + |Î”p_i(t)|)<br/>Ã— diversity_factor Ã— temporal_weight
            
            Dec->>Dec: ğŸ“Š Update Diversity Index
            Dec->>WS: âš¡ energy_update Event (E=847.3J)
            Dec->>WS: ğŸ¯ token_stream Event
            Dec->>WS: ğŸ“ˆ diversity_index Event (0.847)
            WS->>UI: ğŸŒŸ Real-time Energy Visualization
            deactivate Dec
        end
        
        Ollama->>Adapter: âœ… Stream Complete (Total: 2.4s)
        deactivate Ollama
        Adapter->>Dec: ğŸ“Š Final Session Metrics
        activate Dec
        Dec->>Dec: ğŸ¯ Calculate Session Energy Total
        Dec->>WS: ğŸ‰ session_complete Event
        Dec->>WS: ğŸ“Š energy_summary Event
        WS->>UI: ğŸ† Session Results Dashboard
        deactivate Dec
        deactivate Adapter
    end

    rect rgb(139, 92, 246, 0.1)
        Note over API,UI: ğŸš€ Phase 3: Turbo Mode Multi-Model Ensemble
        opt Hardware Tier: Mid/High Only
            API->>Adapter: ğŸš€ Turbo Generate Request
            Note right of API: ğŸ¯ Ensemble Config:<br/>Multiple models in parallel<br/>Hardware tier validation required
            activate Adapter
            
            Adapter->>Adapter: ğŸ·ï¸ Validate Tier Policy (Mid/High)
            
            par Llama Model
                Adapter->>Ollama: ğŸ¦™ Generate (Llama2:13B)
                activate Ollama
                Ollama->>Adapter: ğŸ¯ Llama Tokens
                deactivate Ollama
            and Mistral Model  
                Adapter->>Ollama: ğŸŒªï¸ Generate (Mistral:7B)
                activate Ollama
                Ollama->>Adapter: ğŸ¯ Mistral Tokens
                deactivate Ollama
            and CodeLlama Model
                Adapter->>Ollama: ğŸ’» Generate (CodeLlama:7B)
                activate Ollama
                Ollama->>Adapter: ğŸ¯ CodeLlama Tokens
                deactivate Ollama
            and Phi Model
                Adapter->>Ollama: Ï† Generate (Phi3:3.8B)
                activate Ollama
                Ollama->>Adapter: ğŸ¯ Phi Tokens
                deactivate Ollama
            end
            
            Adapter->>Dec: ğŸŒˆ Ensemble Token Stream (4 Models)
            activate Dec
            Dec->>Dec: ğŸ”¬ Calculate Model Interference/Resonance
            Dec->>Dec: ğŸ“Š Compute Diversity Index (Multi-Model)
            Dec->>Dec: âš¡ Calculate Ensemble Energy
            Dec->>WS: ğŸŒŸ ensemble_energy Event
            Dec->>WS: ğŸ­ model_synchronization Event
            Dec->>WS: ğŸŒˆ diversity_peak Event
            WS->>UI: ğŸ† Multi-Model Energy Visualization
            deactivate Dec
            deactivate Adapter
        end
    end

    rect rgb(245, 158, 11, 0.1)
        Note over API,UI: ğŸ©º Phase 4: Health Monitoring & Performance
        loop Every 10 seconds
            API->>Adapter: ğŸ’“ Health Check Request
            Adapter->>Ollama: ğŸ” GET /api/ps (Process Status)
            Ollama->>Adapter: ğŸ“Š Model Status + Memory Usage
            Adapter->>API: ğŸŸ¢ Health Report
            API->>WS: ğŸ’š ollama_health Event
            WS->>UI: ğŸ“Š System Health Dashboard
        end
        
        loop Every 16.67ms (60Hz)
            Dec->>WS: âš¡ Real-time Energy Stream
            WS->>UI: ğŸŒŸ 60Hz Energy Truth Visualization
        end
    end

    Note over API,UI: âœ… Integration Complete: Local AI â€¢ Energy Truth â€¢ 60Hz Performance
